/**
 * Sync Service
 * 
 * Handles background synchronization of local data with Supabase cloud storage.
 * Implements queue-based sync with retry logic, exponential backoff, and
 * conflict resolution.
 * 
 * **Key Features**:
 * - Queue-based sync (processes pending operations)
 * - Retry logic with exponential backoff (max 3 attempts)
 * - Network timeout protection (30 seconds)
 * - Mutex to prevent concurrent syncs
 * - Deletes processed before inserts/updates (avoids FK conflicts)
 * - Idempotent operations using supabase_id
 * 
 * **Sync Order**:
 * 1. Deletes (processed first to avoid foreign key conflicts)
 * 2. Inserts
 * 3. Updates
 * 
 * @module services/syncService
 */

import { supabase } from '../lib/supabase';
import type { StorageAdapter } from '../adapters/storage';
import { logger } from '../utils/logger';
import { decryptContent } from '../utils/encryption';

/**
 * Mutex to prevent concurrent sync operations
 * 
 * Ensures only one sync runs at a time to avoid race conditions
 * and data corruption.
 * 
 * @internal
 */
class SyncMutex {
  private locked: boolean = false;
  private queue: Array<() => void> = [];

  async acquire(): Promise<void> {
    if (!this.locked) {
      this.locked = true;
      return Promise.resolve();
    }

    return new Promise<void>((resolve) => {
      this.queue.push(resolve);
    });
  }

  release(): void {
    const next = this.queue.shift();
    if (next) {
      next();
    } else {
      this.locked = false;
    }
  }

  isLocked(): boolean {
    return this.locked;
  }
}

const syncMutex = new SyncMutex();

/** Network timeout for Supabase operations (30 seconds) */
const NETWORK_TIMEOUT_MS = 30000;

/** Maximum retry attempts before marking as failed */
const MAX_RETRY_COUNT = 3;

/** Base delay for exponential backoff (in milliseconds) */
const BASE_BACKOFF_MS = 1000;

/**
 * Wrap a promise with a timeout
 * Throws an error if the operation takes longer than the specified timeout
 */
function withTimeout<T>(promise: Promise<T>, timeoutMs: number, operation: string): Promise<T> {
  return Promise.race([
    promise,
    new Promise<T>((_, reject) =>
      setTimeout(
        () => reject(new Error(`${operation} timed out after ${timeoutMs}ms`)),
        timeoutMs
      )
    ),
  ]);
}

/**
 * Sync result for tracking success/failures
 */
export interface SyncResult {
  synced: number;
  failed: number;
  errors: string[];
}

/**
 * Sync queue item from SQLite
 */
interface SyncQueueItem {
  id: string;
  table_name: string;
  record_id: string;
  operation: 'insert' | 'update' | 'delete';
  supabase_id: string | null;
  retry_count: number;
  last_error: string | null;
}

/**
 * Journal entry from local SQLite
 */
interface LocalJournalEntry {
  id: string;
  user_id: string;
  encrypted_title: string | null;
  encrypted_body: string;
  encrypted_mood: string | null;
  encrypted_craving: string | null;
  encrypted_tags: string | null;
  created_at: string;
  updated_at: string;
  sync_status: string;
  supabase_id: string | null;
}

/**
 * Step work from local SQLite
 */
interface LocalStepWork {
  id: string;
  user_id: string;
  step_number: number;
  question_number: number;
  encrypted_answer: string | null;
  is_complete: number;
  completed_at: string | null;
  created_at: string;
  updated_at: string;
  sync_status: string;
  supabase_id: string | null;
}

/**
 * Daily check-in from local SQLite
 */
interface LocalDailyCheckIn {
  id: string;
  user_id: string;
  check_in_type: 'morning' | 'evening';
  check_in_date: string;
  encrypted_intention: string | null;
  encrypted_reflection: string | null;
  encrypted_mood: string | null;
  encrypted_craving: string | null;
  created_at: string;
  updated_at: string;
  sync_status: string;
  supabase_id: string | null;
}

/**
 * Favorite meeting from local SQLite
 */
interface LocalFavoriteMeeting {
  id: string;
  user_id: string;
  meeting_id: string;
  encrypted_notes: string | null;
  notification_enabled: number;
  created_at: string;
  sync_status: string;
  supabase_id: string | null;
}

/**
 * Reading reflection from local SQLite
 */
interface LocalReadingReflection {
  id: string;
  user_id: string;
  reading_id: string;
  reading_date: string;
  encrypted_reflection: string;
  word_count: number;
  created_at: string;
  updated_at: string;
  sync_status: string;
  supabase_id: string | null;
}

/**
 * Generate a UUID v4
 */
function generateUUID(): string {
  if (typeof crypto !== 'undefined' && typeof crypto.randomUUID === 'function') {
    return crypto.randomUUID();
  }
  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, (c) => {
    const r = (Math.random() * 16) | 0;
    const v = c === 'x' ? r : (r & 0x3) | 0x8;
    return v.toString(16);
  });
}

/**
 * Sync a single journal entry to Supabase
 * Maps local encrypted fields to Supabase schema
 */
export async function syncJournalEntry(
  db: StorageAdapter,
  entryId: string,
  userId: string
): Promise<{ success: boolean; error?: string }> {
  try {
    // Fetch journal entry from local database
    const entry = await db.getFirstAsync<LocalJournalEntry>(
      'SELECT * FROM journal_entries WHERE id = ? AND user_id = ?',
      [entryId, userId]
    );

    if (!entry) {
      return { success: false, error: 'Journal entry not found' };
    }

    // Generate UUID for Supabase if not already synced
    const supabaseId = entry.supabase_id || generateUUID();

    // Parse tags if they exist (local stores as encrypted JSON string)
    let tags: string[] = [];
    if (entry.encrypted_tags) {
      try {
        // Tags are encrypted as JSON string, we need to keep them encrypted
        // but Supabase expects TEXT[] array, so we'll send as single encrypted item
        tags = [entry.encrypted_tags];
      } catch (err) {
        logger.warn('Failed to parse tags, using empty array');
      }
    }

    // Map local schema to Supabase schema
    const supabaseData = {
      id: supabaseId,
      user_id: userId,
      title: entry.encrypted_title || '', // Encrypted title
      content: entry.encrypted_body, // Encrypted content
      mood: entry.encrypted_mood, // Encrypted mood (nullable)
      tags, // Array with encrypted tags
      created_at: entry.created_at,
      updated_at: entry.updated_at,
    };

    // Upsert to Supabase (insert or update) with timeout
    const response = await withTimeout(
      Promise.resolve(supabase
        .from('journal_entries')
        .upsert(supabaseData, {
          onConflict: 'id',
        })),
      NETWORK_TIMEOUT_MS,
      'Journal entry upsert'
    );
    const supabaseError = (response as { error: { message: string } | null }).error;

    if (supabaseError) {
      logger.error('Supabase upsert failed for journal entry', supabaseError);
      return { success: false, error: supabaseError.message };
    }

    // Update local record with supabase_id and mark as synced
    await db.runAsync(
      `UPDATE journal_entries
       SET supabase_id = ?, sync_status = 'synced', updated_at = ?
       WHERE id = ?`,
      [supabaseId, new Date().toISOString(), entryId]
    );

    logger.info('Journal entry synced successfully', { entryId, supabaseId });
    return { success: true };
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : 'Unknown error';
    logger.error('Failed to sync journal entry', { entryId, error });
    return { success: false, error: errorMessage };
  }
}

/**
 * Sync a single step work record to Supabase
 * Note: Supabase step_work schema differs from local (content vs question_number/encrypted_answer)
 */
export async function syncStepWork(
  db: StorageAdapter,
  stepWorkId: string,
  userId: string
): Promise<{ success: boolean; error?: string }> {
  try {
    // Fetch step work from local database
    const stepWork = await db.getFirstAsync<LocalStepWork>(
      'SELECT * FROM step_work WHERE id = ? AND user_id = ?',
      [stepWorkId, userId]
    );

    if (!stepWork) {
      return { success: false, error: 'Step work not found' };
    }

    // Generate or reuse Supabase ID
    const supabaseId = stepWork.supabase_id || generateUUID();

    // Map local schema to Supabase schema
    // Supabase has simpler schema: just step_number + content (encrypted)
    // We'll combine question_number into content for now
    const content = stepWork.encrypted_answer || '';

    const supabaseData = {
      id: supabaseId,
      user_id: userId,
      step_number: stepWork.step_number,
      content, // Encrypted answer
      is_completed: stepWork.is_complete === 1,
      created_at: stepWork.created_at,
      updated_at: stepWork.updated_at,
    };

    // Upsert to Supabase with timeout
    const response = await withTimeout(
      Promise.resolve(supabase
        .from('step_work')
        .upsert(supabaseData, {
          onConflict: 'id',
        })),
      NETWORK_TIMEOUT_MS,
      'Step work upsert'
    );
    const supabaseError = (response as { error: { message: string } | null }).error;

    if (supabaseError) {
      logger.error('Supabase upsert failed for step work', supabaseError);
      return { success: false, error: supabaseError.message };
    }

    // Mark as synced in local database and store supabase_id
    await db.runAsync(
      `UPDATE step_work
       SET supabase_id = ?, sync_status = 'synced', updated_at = ?
       WHERE id = ?`,
      [supabaseId, new Date().toISOString(), stepWorkId]
    );

    logger.info('Step work synced successfully', { stepWorkId, supabaseId });
    return { success: true };
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : 'Unknown error';
    logger.error('Failed to sync step work', { stepWorkId, error });
    return { success: false, error: errorMessage };
  }
}

/**
 * Sync a single daily check-in to Supabase
 * Maps local encrypted fields to Supabase schema
 *
 * Local schema fields → Supabase schema fields:
 * - check_in_type → checkin_type (note: no underscore in Supabase)
 * - encrypted_intention → intention (morning check-ins)
 * - encrypted_reflection → notes (evening check-ins - combined with wins/challenges)
 * - encrypted_mood → mood
 * - encrypted_craving → day_rating (converted: 0-10 craving → inverted 1-10 rating)
 */
export async function syncDailyCheckIn(
  db: StorageAdapter,
  checkInId: string,
  userId: string
): Promise<{ success: boolean; error?: string }> {
  try {
    // Fetch check-in from local database
    const checkIn = await db.getFirstAsync<LocalDailyCheckIn>(
      'SELECT * FROM daily_checkins WHERE id = ? AND user_id = ?',
      [checkInId, userId]
    );

    if (!checkIn) {
      return { success: false, error: 'Daily check-in not found' };
    }

    // Generate UUID for Supabase if not already synced
    const supabaseId = checkIn.supabase_id || generateUUID();

    // Map local schema to Supabase schema
    // The Supabase schema has different field structure for morning vs evening
    const supabaseData: Record<string, unknown> = {
      id: supabaseId,
      user_id: userId,
      checkin_type: checkIn.check_in_type, // Note: no underscore in Supabase
      checkin_date: checkIn.check_in_date,
      created_at: checkIn.created_at,
      updated_at: checkIn.updated_at || new Date().toISOString(),
    };

    // Map fields based on check-in type
    if (checkIn.check_in_type === 'morning') {
      // Morning check-in: intention field
      supabaseData.intention = checkIn.encrypted_intention; // Already encrypted
      supabaseData.mood = checkIn.encrypted_mood;
    } else {
      // Evening check-in: reflection goes to notes
      supabaseData.notes = checkIn.encrypted_reflection; // Already encrypted
      supabaseData.mood = checkIn.encrypted_mood;
      // Convert craving (0-10) to day_rating (1-10, inverted: high craving = low rating)
      // If craving is encrypted, we store it as-is for now
      if (checkIn.encrypted_craving) {
        // Preserve encrypted craving data for privacy
        supabaseData.challenges_faced = checkIn.encrypted_craving;

        // Provide a numeric day_rating if we can safely derive it
        try {
          const decrypted = await decryptContent(checkIn.encrypted_craving);
          const craving = Number.parseInt(decrypted, 10);
          if (!Number.isNaN(craving)) {
            const rating = Math.max(1, Math.min(10, 11 - craving));
            supabaseData.day_rating = rating;
          }
        } catch {
          // Ignore decryption failures; keep encrypted fallback only
        }
      }
    }

    // Upsert to Supabase (insert or update) with timeout
    const response = await withTimeout(
      Promise.resolve(supabase
        .from('daily_checkins')
        .upsert(supabaseData, {
          onConflict: 'id',
        })),
      NETWORK_TIMEOUT_MS,
      'Daily check-in upsert'
    );
    const supabaseError = (response as { error: { message: string } | null }).error;

    if (supabaseError) {
      logger.error('Supabase upsert failed for daily check-in', supabaseError);
      return { success: false, error: supabaseError.message };
    }

    // Update local record with supabase_id and mark as synced
    await db.runAsync(
      `UPDATE daily_checkins
       SET supabase_id = ?, sync_status = 'synced', updated_at = ?
       WHERE id = ?`,
      [supabaseId, new Date().toISOString(), checkInId]
    );

    logger.info('Daily check-in synced successfully', { checkInId, supabaseId, type: checkIn.check_in_type });
    return { success: true };
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : 'Unknown error';
    logger.error('Failed to sync daily check-in', { checkInId, error });
    return { success: false, error: errorMessage };
  }
}

/**
 * Sync a single favorite meeting to Supabase
 * User's favorite meetings are encrypted behavioral data
 */
export async function syncFavoriteMeeting(
  db: StorageAdapter,
  favoriteId: string,
  userId: string
): Promise<{ success: boolean; error?: string }> {
  try {
    // Fetch favorite meeting from local database
    const favorite = await db.getFirstAsync<LocalFavoriteMeeting>(
      'SELECT * FROM favorite_meetings WHERE id = ? AND user_id = ?',
      [favoriteId, userId]
    );

    if (!favorite) {
      return { success: false, error: 'Favorite meeting not found' };
    }

    // Generate UUID for Supabase if not already synced
    const supabaseId = favorite.supabase_id || generateUUID();

    // Map local schema to Supabase schema
    const supabaseData = {
      id: supabaseId,
      user_id: userId,
      meeting_id: favorite.meeting_id,
      notes: favorite.encrypted_notes, // Already encrypted
      notification_enabled: favorite.notification_enabled === 1,
      created_at: favorite.created_at,
      updated_at: new Date().toISOString(),
    };

    // Upsert to Supabase (insert or update) with timeout
    const response = await withTimeout(
      Promise.resolve(supabase
        .from('favorite_meetings')
        .upsert(supabaseData, {
          onConflict: 'id',
        })),
      NETWORK_TIMEOUT_MS,
      'Favorite meeting upsert'
    );
    const supabaseError = (response as { error: { message: string } | null }).error;

    if (supabaseError) {
      logger.error('Supabase upsert failed for favorite meeting', supabaseError);
      return { success: false, error: supabaseError.message };
    }

    // Update local record with supabase_id and mark as synced
    await db.runAsync(
      `UPDATE favorite_meetings
       SET supabase_id = ?, sync_status = 'synced'
       WHERE id = ?`,
      [supabaseId, favoriteId]
    );

    logger.info('Favorite meeting synced successfully', { favoriteId, supabaseId });
    return { success: true };
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : 'Unknown error';
    logger.error('Failed to sync favorite meeting', { favoriteId, error });
    return { success: false, error: errorMessage };
  }
}

/**
 * Sync a single reading reflection to Supabase
 * Maps local encrypted fields to Supabase schema
 */
export async function syncReadingReflection(
  db: StorageAdapter,
  reflectionId: string,
  userId: string
): Promise<{ success: boolean; error?: string }> {
  try {
    // Get the reflection from local database
    const reflection = await db.getFirstAsync<LocalReadingReflection>(
      `SELECT id, user_id, reading_id, reading_date, encrypted_reflection, 
       word_count, created_at, updated_at, sync_status, supabase_id 
       FROM reading_reflections WHERE id = ? AND user_id = ?`,
      [reflectionId, userId]
    );

    if (!reflection) {
      return {
        success: false,
        error: `Reading reflection not found: ${reflectionId}`,
      };
    }

    // Generate Supabase ID if needed
    const supabaseId = reflection.supabase_id || generateUUID();

    // Prepare data for Supabase (using established schema patterns)
    const supabaseData = {
      id: supabaseId,
      user_id: reflection.user_id,
      reading_id: reflection.reading_id,
      reading_date: reflection.reading_date,
      encrypted_reflection: reflection.encrypted_reflection,
      word_count: reflection.word_count,
      created_at: reflection.created_at,
      updated_at: reflection.updated_at,
    };

    // Upsert to Supabase (insert or update) with timeout
    const response = await withTimeout(
      Promise.resolve(supabase
        .from('reading_reflections')
        .upsert(supabaseData, {
          onConflict: 'id',
        })),
      NETWORK_TIMEOUT_MS,
      'Reading reflection upsert'
    );
    const supabaseError = (response as { error: { message: string } | null }).error;

    if (supabaseError) {
      logger.error('Supabase upsert failed for reading reflection', supabaseError);
      return { success: false, error: supabaseError.message };
    }

    // Update local record with supabase_id and mark as synced
    await db.runAsync(
      `UPDATE reading_reflections
       SET supabase_id = ?, sync_status = 'synced'
       WHERE id = ?`,
      [supabaseId, reflectionId]
    );

    logger.info('Reading reflection synced successfully', { reflectionId, supabaseId });
    return { success: true };
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : 'Unknown error';
    logger.error('Failed to sync reading reflection', { reflectionId, error });
    return { success: false, error: errorMessage };
  }
}

/**
 * Delete a record from Supabase
 */
async function deleteFromSupabase(
  tableName: string,
  supabaseId: string,
  userId: string
): Promise<{ success: boolean; error?: string }> {
  try {
    const response = await withTimeout(
      Promise.resolve(supabase
        .from(tableName)
        .delete()
        .eq('id', supabaseId)
        .eq('user_id', userId)),
      NETWORK_TIMEOUT_MS,
      `Delete from ${tableName}`
    );
    const supabaseError = (response as { error: { message: string } | null }).error;

    if (supabaseError) {
      logger.error('Supabase delete failed', { tableName, supabaseId, error: supabaseError });
      return { success: false, error: supabaseError.message };
    }

    logger.info('Record deleted from Supabase', { tableName, supabaseId });
    return { success: true };
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : 'Unknown error';
    logger.error('Failed to delete from Supabase', { tableName, supabaseId, error });
    return { success: false, error: errorMessage };
  }
}

/**
 * Process a single sync queue item
 * Handles routing to correct sync function and result handling
 */
async function processSyncItem(
  db: StorageAdapter,
  item: SyncQueueItem,
  userId: string
): Promise<{ success: boolean; error?: string }> {
  // Handle delete operations
  if (item.operation === 'delete') {
    if (item.supabase_id) {
      return deleteFromSupabase(item.table_name, item.supabase_id, userId);
    } else {
      // Record was never synced to cloud, so nothing to delete remotely
      logger.info('Delete skipped - record was never synced to cloud', {
        tableName: item.table_name,
        recordId: item.record_id,
        operation: item.operation,
      });
      return { success: true };
    }
  }

  // Handle insert/update operations - route to appropriate sync function
  switch (item.table_name) {
    case 'journal_entries':
      return syncJournalEntry(db, item.record_id, userId);
    case 'step_work':
      return syncStepWork(db, item.record_id, userId);
    case 'daily_checkins':
      return syncDailyCheckIn(db, item.record_id, userId);
    case 'favorite_meetings':
      return syncFavoriteMeeting(db, item.record_id, userId);
    case 'reading_reflections':
      return syncReadingReflection(db, item.record_id, userId);
    default:
      return {
        success: false,
        error: `Unknown table: ${item.table_name}`,
      };
  }
}

/**
 * Handle the result of a sync operation
 * Updates queue item on failure, removes on success
 */
async function handleSyncResult(
  db: StorageAdapter,
  item: SyncQueueItem,
  syncResult: { success: boolean; error?: string },
  result: SyncResult
): Promise<void> {
  if (syncResult.success) {
    // Remove from sync queue on success
    await db.runAsync('DELETE FROM sync_queue WHERE id = ?', [item.id]);
    result.synced++;
    logger.info('Sync item processed successfully', {
      tableName: item.table_name,
      recordId: item.record_id,
      operation: item.operation,
    });
  } else {
    // Increment retry count and store error
    const newRetryCount = item.retry_count + 1;

    // Check if we've exceeded max retries
    if (newRetryCount >= MAX_RETRY_COUNT) {
      // Mark as failed permanently after max retries
      await db.runAsync(
        `UPDATE sync_queue
         SET retry_count = ?, last_error = ?, failed_at = ?
         WHERE id = ?`,
        [newRetryCount, syncResult.error || 'Unknown error', new Date().toISOString(), item.id]
      );
      logger.error('Sync item permanently failed after max retries', {
        queueItemId: item.id,
        tableName: item.table_name,
        recordId: item.record_id,
        operation: item.operation,
        retryCount: newRetryCount,
        error: syncResult.error,
      });
    } else {
      // Still have retries left
      await db.runAsync(
        `UPDATE sync_queue
         SET retry_count = ?, last_error = ?
         WHERE id = ?`,
        [newRetryCount, syncResult.error || 'Unknown error', item.id]
      );
      logger.warn('Sync failed, will retry', {
        queueItemId: item.id,
        tableName: item.table_name,
        recordId: item.record_id,
        operation: item.operation,
        retryCount: newRetryCount,
        maxRetries: MAX_RETRY_COUNT,
        error: syncResult.error,
      });
    }

    result.failed++;
    result.errors.push(
      `[${item.operation}] ${item.table_name}/${item.record_id}: ${syncResult.error || 'Unknown error'}`
    );
  }
}

/**
 * Process the sync queue with batch processing and retry logic
 *
 * IMPORTANT: Deletes are processed BEFORE inserts/updates to avoid
 * foreign key conflicts and ensure data consistency.
 *
 * @param db - Storage adapter instance (SQLite on mobile, IndexedDB on web)
 * @param userId - Current user ID
 * @param maxBatchSize - Maximum items to process per batch (default: 50)
 * @returns SyncResult with counts and errors
 */
export async function processSyncQueue(
  db: StorageAdapter,
  userId: string,
  maxBatchSize: number = 50
): Promise<SyncResult> {
  // Prevent concurrent sync operations using mutex
  if (syncMutex.isLocked()) {
    logger.info('Sync already in progress, skipping duplicate call');
    return { synced: 0, failed: 0, errors: ['Sync already in progress'] };
  }

  await syncMutex.acquire();

  const result: SyncResult = {
    synced: 0,
    failed: 0,
    errors: [],
  };

  try {
    // Fetch pending sync items, ordered by creation time
    // Limit to maxBatchSize to prevent overwhelming the system
    // Exclude items that have permanently failed (failed_at IS NOT NULL)
    const queueItems = await db.getAllAsync<SyncQueueItem>(
      `SELECT * FROM sync_queue
       WHERE retry_count < ?
       AND (failed_at IS NULL OR failed_at = '')
       ORDER BY created_at ASC
       LIMIT ?`,
      [MAX_RETRY_COUNT, maxBatchSize]
    );

    if (queueItems.length === 0) {
      logger.info('Sync queue is empty');
      return result;
    }

    // Separate deletes from inserts/updates
    // Process deletes FIRST to avoid foreign key conflicts
    const deleteItems = queueItems.filter(item => item.operation === 'delete');
    const upsertItems = queueItems.filter(item => item.operation !== 'delete');

    logger.info('Processing sync queue', {
      total: queueItems.length,
      deletes: deleteItems.length,
      upserts: upsertItems.length,
    });

    // Phase 1: Process all delete operations first
    if (deleteItems.length > 0) {
      logger.info('Phase 1: Processing delete operations', { count: deleteItems.length });
      for (const item of deleteItems) {
        const syncResult = await processSyncItem(db, item, userId);
        await handleSyncResult(db, item, syncResult, result);
      }
    }

    // Phase 2: Process all insert/update operations with exponential backoff for retries
    if (upsertItems.length > 0) {
      logger.info('Phase 2: Processing insert/update operations', { count: upsertItems.length });
      for (const item of upsertItems) {
        // Apply exponential backoff BEFORE retrying (not on first attempt)
        if (item.retry_count > 0) {
          const delayMs = Math.min(
            BASE_BACKOFF_MS * Math.pow(2, item.retry_count - 1),
            30000 // Cap at 30 seconds
          );
          logger.info('Applying exponential backoff before retry', {
            queueItemId: item.id,
            retryCount: item.retry_count,
            delayMs,
          });
          await new Promise((resolve) => setTimeout(resolve, delayMs));
        }

        const syncResult = await processSyncItem(db, item, userId);
        await handleSyncResult(db, item, syncResult, result);
      }
    }

    logger.info('Sync queue processing complete', {
      synced: result.synced,
      failed: result.failed,
      deletesProcessed: deleteItems.length,
      upsertsProcessed: upsertItems.length,
    });

    return result;
  } catch (error) {
    logger.error('Sync queue processing failed', error);
    result.errors.push(error instanceof Error ? error.message : 'Unknown error');
    return result;
  } finally {
    // Always release the mutex, even if sync fails
    syncMutex.release();
  }
}

/**
 * Add a record to the sync queue
 * This should be called whenever a record is created, updated, or deleted
 *
 * @param db - Storage adapter instance (SQLite on mobile, IndexedDB on web)
 * @param tableName - Name of the table (journal_entries, daily_checkins, step_work)
 * @param recordId - ID of the record to sync
 * @param operation - Type of operation (insert, update, delete)
 * @param supabaseId - Optional Supabase ID (required for delete operations)
 */
export async function addToSyncQueue(
  db: StorageAdapter,
  tableName: string,
  recordId: string,
  operation: 'insert' | 'update' | 'delete',
  supabaseId?: string | null
): Promise<void> {
  try {
    const queueId = `sync_${generateUUID()}`;
    const now = new Date().toISOString();

    await db.runAsync(
      `INSERT OR REPLACE INTO sync_queue (id, table_name, record_id, operation, supabase_id, created_at, retry_count)
       VALUES (?, ?, ?, ?, ?, ?, 0)`,
      [queueId, tableName, recordId, operation, supabaseId || null, now]
    );

    logger.info('Added to sync queue', { tableName, recordId, operation, supabaseId: supabaseId || null });
  } catch (error) {
    logger.error('Failed to add to sync queue', { tableName, recordId, error });
    throw error;
  }
}

/**
 * Queue a delete operation with proper supabase_id capture
 * This helper fetches the supabase_id before the record is deleted
 *
 * @param db - Storage adapter instance (SQLite on mobile, IndexedDB on web)
 * @param tableName - Name of the table
 * @param recordId - ID of the record to delete
 * @param userId - User ID for ownership verification
 */
export async function addDeleteToSyncQueue(
  db: StorageAdapter,
  tableName: string,
  recordId: string,
  userId: string
): Promise<void> {
  try {
    // Fetch the supabase_id before deletion
    const record = await db.getFirstAsync<{ supabase_id: string | null }>(
      `SELECT supabase_id FROM ${tableName} WHERE id = ? AND user_id = ?`,
      [recordId, userId]
    );

    const supabaseId = record?.supabase_id || null;

    // Add to sync queue with the supabase_id
    await addToSyncQueue(db, tableName, recordId, 'delete', supabaseId);

    if (!supabaseId) {
      logger.info('Delete queued for unsynced record - will skip cloud delete', {
        tableName,
        recordId,
      });
    }
  } catch (error) {
    logger.error('Failed to queue delete operation', { tableName, recordId, error });
    throw error;
  }
}
